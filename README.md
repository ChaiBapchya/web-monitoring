# Web Monitoring

This repository is for EDGI [Web Monitoring Project](https://github.com/edgi-govdata-archiving/web-monitoring) documentation and project-wide issue management.

EDGI is already monitoring tens of thousands of pages and will eventually be monitoring tens of millions (or even as many as ~1 billion). Currently there is a lot of manual labour that goes into reviewing all changes, regardless of whether they are meaningful or not. Any system will need to emphasize usability of the UI and efficiency of computational resources.

## Project Goals

The purpose of the system is to enable analysts to quickly review monitored government websites in order to report on [__meaningful changes__](#identifying-meaningful-changes). The Website Monitoring automated system aims to make these changes easy to track, review, and report on.

For more, see [the Version Tracking page on the EDGI website](https://envirodatagov.org/version-tracking/) and watch this
[50-minute Analyst training video](https://www.dropbox.com/s/ciixvu612ktf4nt/new_tracking_training.mp4?dl=0).

## How to Help

Start by reading the Project Overview below and thinking about which aspects of
the projects spark your interest.

We expect to deploy a minimal operational version of this application by the
end of March. Starting from that baseline, we will post many feature requests,
bug reports, and documentation needs.

See also the [contributor guidelines](https://github.com/edgi-govdata-archiving/web-monitoring/blob/master/CONTRIBUTING.md).

## Project Overview

### Specification

1. Access captured data (starting with HTML, later encompassing more types) from
   multiple archival sources including Versionista, PageFreezer, and the
   Internet Archive.
2. Compare version of the same page over time --- potentially using multiple
   different strategies.
3. Automatically filter out "uninteresting" or repetitive changes: for example,
   the "Page Last Viewed" timestamp updated or the same news article was added
   to 100 pages from the same website.
4. Prioritize the changes most likely to be "interesting," meaning that some
   item of importance to fact-based governance was deleted or changed in a
   harmful way.
5. Present changes to human analysts with useful visualizations and statistics
   to help them differentiate interesting changes. Each user will have been
   assigned a "subdomain", a full or partial government domain that has been
   identified as relevant to fact-based governance.
6. Collect annotations from the analysts. Use this to flag and draw broader
   public attention to important changes. Also use it to feed back into the
   filtering and priotization process. (That is, use it to train models.)

### Definition of Terms

* Page: a web page that might change over time.
* Version: a snapshot of a Page at a specific time (saved as HTML, for now).
* Change: two different Versions of the same Page.
* Diff: a representation of a Change: this could be a plain text `diff` (as in
  the UNIX comand line utility) or a richer representation (as in the JSON blobs
  returned by PageFreezer) that takes into account HTML semantics.
* Annotation: a set of key-value pairs evaluating a given Change, submitted by a
  human analyst or generated by an automated process. There can be multiple
  Annotations for a given Change.

### Architecture

The project is current divided into three repositories handling complementary aspects of the task. They can be developed and upgraded semi-independently, communicating via agreed-upon interfaces:
* [**web-monitoring-db**](https://github.com/edgi-govdata-archiving/web-monitoring-db)  
  A Ruby on Rails app for serves diffs from a database and collects
  human-entered annotations.
* [**web-monitoring-ui**](https://github.com/edgi-govdata-archiving/web-monitoring-ui)  
  Front-end code (in TypeScript) provides useful views of the diffs. It
  communicates with the Rails app via JSON.
* [**web-monitoring-processing**](https://github.com/edgi-govdata-archiving/web-monitoring-processing)  
  A Python backend ingests new captured HTML, computes diffs (for now, by
  querying PageFreezer), performs prioritization/filtering, and populates
  databases for Rails app.

### Deployment Plan

The software will be deployed on Google Cloud, with each component running in a
separate Docker container.

### Identifying "Meaningful Changes"

The vast majority of changes to web pages are not relevant to analysts and we want to avoid presenting those irrelevant changes to analysts at all. It is, of course, not trivial to identify "meaningful" changes immediately, and we expect that analysts will always be involved in a decision about whether some changes are "important" or not. However, as we expand from 10<sup>4</sup> to 10<sup>7</sup> webpages, we need to drastically reduce the number of pages that analysts look at. 

Some examples of **meaningless** changes: 
- it's not unusual for a page to have a view counter on the bottom. In this case, the page changes **by definition** every time you view it.
- many sites have "content sliders" or news feeds that update periodically. This change may be "meaningful", in that it's interesting to see news updates. But it's only interesting once, not (as is sometimes seen) 1000 or 10000 times.

An example of a **meaningful** change: 
- In February, we noticed a systematic replacement of the word "impact" with the word "effect" on one website. This change is very interesting because while "impact" and "effect" have similar meanings, "impact" is a **stronger** word. So there is an effort being made to **weaken** the language on existing sites. Our question is in part: what tools would we need in order to have this change **flagged** by our tools and presented to the analyst as **potentially interesting**?

### Sample Data

[`example-data`](./example-data) contains examples of website changes:

- `falsepos-...` files are cases any filter should catch
- `truepos...` files are cases of changes we care about

This is a small but illustrative sample. Many more samples will be made
available as soon as possible.
